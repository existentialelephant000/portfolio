{"ast":null,"code":"var _jsxFileName = \"/Users/jacksonho/Desktop/portfolio/src/pages/Search.js\";\nimport ProjHeader from \"./components/ProjHeader\";\nimport searchColor from \"./images/searchColor.png\";\nimport './Search.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nimport { Fragment as _Fragment } from \"react/jsx-dev-runtime\";\nexport function Search() {\n  return /*#__PURE__*/_jsxDEV(_Fragment, {\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      class: \"search\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n          style: {\n            fontSize: '75px',\n            display: 'inline-block'\n          },\n          children: \"search\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 10,\n          columnNumber: 17\n        }, this), /*#__PURE__*/_jsxDEV(\"img\", {\n          style: {\n            display: 'inline-block',\n            maxHeight: '3vw',\n            marginLeft: '3vw'\n          },\n          src: searchColor\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 11,\n          columnNumber: 17\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 9,\n        columnNumber: 13\n      }, this), /*#__PURE__*/_jsxDEV(ProjHeader, {\n        title: \"the project\",\n        text: \"Based in python, the premise of search was to create a search engine based on word relevance and PageRank algorithms, famously implented by Google in 1998.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 13,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 17,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"h1\", {\n        children: \"how it works\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 18,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"* The following was adapted from the csci0200 assignment. All rights reserved.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 19,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: \"One could determine which documents are relevant to a query just by comparing the terms in the query to those in the documents. This is how search engines used to work. Then in the 1990s, Google was founded using a different approach based on the PageRank algorithm (designed by the founders). The algorithm ranks pages based on the links among them (without considering the content), with pages that get linked to by other pages (more \\u201Cauthoritative\\u201D pages) getting priority in the results. Here are the key principles underlying the design of PageRank:\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 20,\n        columnNumber: 9\n      }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 24,\n        columnNumber: 120\n      }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n        children: \"The more pages that link to a page j, the more authoritative j should be. For example, if \\u201CBlog Brown\\u201D is linked to by 5 web pages, and the Wikipedia article on \\u201CProvidence, Rhode Island\\u201D is linked to by 500 pages, then it makes sense to consider the Wikipedia article more authoritative.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 25,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 27,\n        columnNumber: 77\n      }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n        children: \"The more authoritative those pages are, the still more authoritative j should be. Now, if \\u201CProvidence Place Mall\\u201D is linked to only by \\u201CProvidence, Rhode Island\\u201D, and \\u201CBlueno\\u201D is linked to only by \\u201CBlog Brown,\\u201D it might not be enough to measure a page\\u2019s authority simply by a count of the number of pages that link to that page. Indeed, it makes sense to consider \\u201CProvidence Place Mall\\u201D more authoritative than \\u201CBlueno\\u201D since it is linked to by a more important page.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 28,\n        columnNumber: 9\n      }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 32,\n        columnNumber: 34\n      }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n        children: \"The fewer links those pages have to pages other than j, the more authoritative j should be. Assume \\u201CResearch at Brown\\u201D is linked to only by a \\u201CNYTimes\\u201D article which links to only 10 other pages, while \\u201CWhy Brown?\\u201D is linked to only by \\u201CBlog Brown\\u201D, which links to 200 other pages. Because the \\\"NYTimes\\u2019\\u2019 page has only a few links, and \\u201CBrown Blog\\u201D has many links, a link from the \\u201CNYTimes\\u201D page can be considered to be more important than a link from the \\u201CBrown Blog\\u201D, leading us to attribute more authority to \\u201CResearch at Brown\\u201D than \\u201CWhy Brown?\\u201D\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 33,\n        columnNumber: 9\n      }, this), \" \", /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 37,\n        columnNumber: 121\n      }, this), /*#__PURE__*/_jsxDEV(\"li\", {\n        children: \"The closer j is to another page k (measured by the number of links that must be followed to get from j to k), the more k\\u2019s score should influence j\\u2019s. For example, if the average path from \\u201CBrown University\\u201D to \\u201CBoeing\\u201D is 100 links, and the average path from \\u201CBrown University\\u201D to \\u201CAmy\\u2019s Personal Website\\u201D is 5 links, then all other things equal, Amy\\u2019s page should be considered more authoritative than Boeing\\u2019s.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 38,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(ProjHeader, {\n        text: \"PageRank uses these principles to compute the authority of each document. The algorithm works  roughly as follows: Each page\\u2019s authority is a number between 0 and 1, where the total authority across all documents  always equals 1. The algorithm starts by assuming that all documents have the same authority. Then, following the  principles, the algorithm updates the authorities based on the links between pages. Since the authority of one page  can affect that of another, this process of refining authorities repeats until the authorities stabilize across all  documents (the underlying mathematics guarantee eventual stabilization). It is important that the total authority in  the system is conserved, so at any point in the converging sequence of page ranks, the total authority in the system  will always sum to 1.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 42,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 50,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(ProjHeader, {\n        title: \"due to the collaboration policy...\",\n        text: \"I cannot say much more about this project. In ideal world, I would describe in more detail how I implemented the project, but for now I cannot :) thanks for understanding!\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 51,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"br\", {}, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 53,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(ProjHeader, {\n        title: \"what i learned\",\n        text: \"In addition to being one of the first projects I implemented from scratch, the premise of  search was so interesting in its own right.  It has also inspired me to think about webscraping \\u2014 it was interesting to parse downloaded wikis, but an even more relavant implementation would involve parsing pages on the internet. This project inspired me to start building a webscraping website, which is  currently in progress.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 54,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 8,\n      columnNumber: 9\n    }, this)\n  }, void 0, false);\n}\n_c = Search;\nvar _c;\n$RefreshReg$(_c, \"Search\");","map":{"version":3,"names":["ProjHeader","searchColor","Search","fontSize","display","maxHeight","marginLeft"],"sources":["/Users/jacksonho/Desktop/portfolio/src/pages/Search.js"],"sourcesContent":["import ProjHeader from \"./components/ProjHeader\"\nimport searchColor from \"./images/searchColor.png\"\nimport './Search.css'\n\nexport function Search() {\n    return (\n        <>\n        <div class=\"search\">\n            <div>\n                <h1 style={{fontSize: '75px', display: 'inline-block'}}>search</h1>\n                <img style={{ display: 'inline-block', maxHeight:'3vw', marginLeft:'3vw'}} src={searchColor} />\n            </div>\n        <ProjHeader title=\"the project\" text=\"Based in python, the premise of search was to create a search engine based on\n        word relevance and PageRank algorithms, famously implented by Google in 1998.\"/>\n        {/* <p style={{display:'inline'}}> * I won't go in depth about how PageRank works here, but if you're interested in learning how it works, you can find more information </p>\n        <a target=\"_blank\" href=\"https://www.geeksforgeeks.org/page-rank-algorithm-implementation/#:~:text=PageRank%20works%20by%20counting%20the,more%20links%20from%20other%20websites.\">here.</a> */}\n        <br/>\n        <h1>how it works</h1>\n        <p>* The following was adapted from the csci0200 assignment. All rights reserved.</p>\n        <p>One could determine which documents are relevant to a query just by comparing the terms in the query to those \n            in the documents. This is how search engines used to work. Then in the 1990s, Google was founded using a different \n            approach based on the PageRank algorithm (designed by the founders). The algorithm ranks pages based on the links \n            among them (without considering the content), with pages that get linked to by other pages (more “authoritative” \n            pages) getting priority in the results. Here are the key principles underlying the design of PageRank:</p> <br/>\n        <li>The more pages that link to a page j, the more authoritative j should be. For example, if “Blog Brown” is linked \n            to by 5 web pages, and the Wikipedia article on “Providence, Rhode Island” is linked to by 500 pages, then it makes \n            sense to consider the Wikipedia article more authoritative.</li><br/>\n        <li>The more authoritative those pages are, the still more authoritative j should be. Now, if “Providence Place Mall” \n            is linked to only by “Providence, Rhode Island”, and “Blueno” is linked to only by “Blog Brown,” it might not be \n            enough to measure a page’s authority simply by a count of the number of pages that link to that page. Indeed, it \n            makes sense to consider “Providence Place Mall” more authoritative than “Blueno” since it is linked to by a more \n            important page.</li> <br/>\n        <li>The fewer links those pages have to pages other than j, the more authoritative j should be. Assume “Research at \n            Brown” is linked to only by a “NYTimes” article which links to only 10 other pages, while “Why Brown?” is linked \n            to only by “Blog Brown”, which links to 200 other pages. Because the \"NYTimes’’ page has only a few links, and \n            “Brown Blog” has many links, a link from the “NYTimes” page can be considered to be more important than a link \n            from the “Brown Blog”, leading us to attribute more authority to “Research at Brown” than “Why Brown?”</li> <br/>\n        <li>The closer j is to another page k (measured by the number of links that must be followed to get from j to k), \n            the more k’s score should influence j’s. For example, if the average path from “Brown University” to “Boeing” is \n            100 links, and the average path from “Brown University” to “Amy’s Personal Website” is 5 links, then all other \n            things equal, Amy’s page should be considered more authoritative than Boeing’s.</li>\n        <ProjHeader text=\"PageRank uses these principles to compute the authority of each document. The algorithm works \n        roughly as follows: Each page’s authority is a number between 0 and 1, where the total authority across all documents \n        always equals 1. The algorithm starts by assuming that all documents have the same authority. Then, following the \n        principles, the algorithm updates the authorities based on the links between pages. Since the authority of one page \n        can affect that of another, this process of refining authorities repeats until the authorities stabilize across all \n        documents (the underlying mathematics guarantee eventual stabilization). It is important that the total authority in \n        the system is conserved, so at any point in the converging sequence of page ranks, the total authority in the system \n        will always sum to 1.\" />\n        <br/>\n        <ProjHeader title=\"due to the collaboration policy...\" text=\"I cannot say much more about this project. In ideal world,\n        I would describe in more detail how I implemented the project, but for now I cannot :) thanks for understanding!\" />\n        <br/>\n        <ProjHeader title=\"what i learned\" text=\"In addition to being one of the first projects I implemented from scratch, the premise of \n            search was so interesting in its own right.  It has also inspired me to think about\n            webscraping — it was interesting to parse downloaded wikis, but an even more relavant implementation\n            would involve parsing pages on the internet. This project inspired me to start building a webscraping website, which is \n            currently in progress.\" />\n        </div>\n        </>\n    )\n}"],"mappings":";AAAA,OAAOA,UAAU,MAAM,yBAAyB;AAChD,OAAOC,WAAW,MAAM,0BAA0B;AAClD,OAAO,cAAc;AAAA;AAAA;AAErB,OAAO,SAASC,MAAM,GAAG;EACrB,oBACI;IAAA,uBACA;MAAK,KAAK,EAAC,QAAQ;MAAA,wBACf;QAAA,wBACI;UAAI,KAAK,EAAE;YAACC,QAAQ,EAAE,MAAM;YAAEC,OAAO,EAAE;UAAc,CAAE;UAAA;QAAA;UAAA;UAAA;UAAA;QAAA,QAAY,eACnE;UAAK,KAAK,EAAE;YAAEA,OAAO,EAAE,cAAc;YAAEC,SAAS,EAAC,KAAK;YAAEC,UAAU,EAAC;UAAK,CAAE;UAAC,GAAG,EAAEL;QAAY;UAAA;UAAA;UAAA;QAAA,QAAG;MAAA;QAAA;QAAA;QAAA;MAAA,QAC7F,eACV,QAAC,UAAU;QAAC,KAAK,EAAC,aAAa;QAAC,IAAI,EAAC;MACyC;QAAA;QAAA;QAAA;MAAA,QAAE,eAGhF;QAAA;QAAA;QAAA;MAAA,QAAK,eACL;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAAqB,eACrB;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAAqF,eACrF;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAI8G,oBAAC;QAAA;QAAA;QAAA;MAAA,QAAK,eACpH;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAEoE;QAAA;QAAA;QAAA;MAAA,QAAK,eACzE;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAIwB,oBAAC;QAAA;QAAA;QAAA;MAAA,QAAK,eAC9B;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAI+G,oBAAC;QAAA;QAAA;QAAA;MAAA,QAAK,eACrH;QAAA;MAAA;QAAA;QAAA;QAAA;MAAA,QAGwF,eACxF,QAAC,UAAU;QAAC,IAAI,EAAC;MAOK;QAAA;QAAA;QAAA;MAAA,QAAG,eACzB;QAAA;QAAA;QAAA;MAAA,QAAK,eACL,QAAC,UAAU;QAAC,KAAK,EAAC,oCAAoC;QAAC,IAAI,EAAC;MACqD;QAAA;QAAA;QAAA;MAAA,QAAG,eACpH;QAAA;QAAA;QAAA;MAAA,QAAK,eACL,QAAC,UAAU;QAAC,KAAK,EAAC,gBAAgB;QAAC,IAAI,EAAC;MAIb;QAAA;QAAA;QAAA;MAAA,QAAG;IAAA;MAAA;MAAA;MAAA;IAAA;EACxB,iBACH;AAEX;AAAC,KAzDeC,MAAM;AAAA;AAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}